{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "WBAoBR8ZAEOW",
        "outputId": "0411bdfa-5367-4a4d-ace6-2b21e1e7a240"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langgraph'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1198825159.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_chat_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTART\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCommand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemorySaver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.types import interrupt, Command\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# -------- Define State --------\n",
        "class workflowState(TypedDict):\n",
        "    preferences: str\n",
        "    breakfast: list[str]\n",
        "    lunch: list[str]\n",
        "    dinner: list[str]\n",
        "\n",
        "# -------- Init LLM --------\n",
        "# llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n",
        "\n",
        "# -------- Nodes --------\n",
        "def get_preferences(state: workflowState):\n",
        "    state[\"preferences\"] = \"vegetarian\"\n",
        "    return {\"preferences\": state[\"preferences\"]}\n",
        "\n",
        "def gen_breakfast(state: workflowState):\n",
        "    # result = llm.invoke(f\"Generate {state['preferences']} breakfast options\")\n",
        "    user_input1 = input(\"Enter breakfast list: \")\n",
        "    # state[\"breakfast\"] = [\"idly\", \"upma\"]\n",
        "    print(f\"{[breakfast]}-------------\")\n",
        "    state[\"breakfast\"] = [item.strip() for item in user_input1.split(\",\")]\n",
        "    return {\"breakfast\": state[\"breakfast\"]}\n",
        "\n",
        "def gen_lunch(state: workflowState):\n",
        "    user_input2 = input(\"Enter lunch list: \")\n",
        "    # state[\"lunch\"] = [\"rice\", \"dal\", \"vegetable curry\"]\n",
        "    state[\"lunch\"] = [item.strip() for item in user_input2.split(\",\")]\n",
        "    return {\"lunch\": state[\"lunch\"]}\n",
        "\n",
        "def gen_dinner(state: workflowState):\n",
        "    user_input3 = input(\"Enter dinner list: \")\n",
        "    # state[\"dinner\"] = [\"chapati\", \"paneer\"]\n",
        "    state[\"dinner\"] = [item.strip() for item in user_input3.split(\",\")]\n",
        "    return {\"dinner\": state[\"dinner\"]}\n",
        "\n",
        "def review_meal(state: workflowState, meal_key: str, next_node: str):\n",
        "    print(f\"\\nReview {meal_key}: {state[meal_key]}\")\n",
        "    decision = interrupt(f\"Approve {meal_key}? Say 'yes' to approve, or anything else to regenerate.\")\n",
        "    if decision == \"yes\":\n",
        "        return Command(goto=next_node)\n",
        "    else:\n",
        "        return Command(goto=f\"gen_{meal_key}\")\n",
        "\n",
        "def review_bf(state: workflowState):\n",
        "    return review_meal(state, \"breakfast\", \"final_bf\")\n",
        "\n",
        "def review_lunch(state: workflowState):\n",
        "    return review_meal(state, \"lunch\", \"final_lunch\")\n",
        "\n",
        "def review_dinner(state: workflowState):\n",
        "    return review_meal(state, \"dinner\", \"final_dinner\")\n",
        "\n",
        "def final_bf(state: workflowState):\n",
        "    return state\n",
        "\n",
        "def final_lunch(state: workflowState):\n",
        "    return state\n",
        "\n",
        "def final_dinner(state: workflowState):\n",
        "    return state\n",
        "\n",
        "def final_review(state: workflowState):\n",
        "    print(\"\\nFinal meal plan:\")\n",
        "    print(\"Breakfast:\", state[\"breakfast\"])\n",
        "    print(\"Lunch:\", state[\"lunch\"])\n",
        "    print(\"Dinner:\", state[\"dinner\"])\n",
        "    return state\n",
        "\n",
        "# -------- Build Graph --------\n",
        "graph = StateGraph(workflowState)\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Nodes\n",
        "graph.add_node(\"get_preferences\", get_preferences)\n",
        "graph.add_node(\"gen_breakfast\", gen_breakfast)\n",
        "graph.add_node(\"review_bf\", review_bf)\n",
        "graph.add_node(\"final_bf\", final_bf)\n",
        "\n",
        "graph.add_node(\"gen_lunch\", gen_lunch)\n",
        "graph.add_node(\"review_lunch\", review_lunch)\n",
        "graph.add_node(\"final_lunch\", final_lunch)\n",
        "\n",
        "graph.add_node(\"gen_dinner\", gen_dinner)\n",
        "graph.add_node(\"review_dinner\", review_dinner)\n",
        "graph.add_node(\"final_dinner\", final_dinner)\n",
        "\n",
        "# Join/final node\n",
        "graph.add_node(\"final_review\", final_review)\n",
        "\n",
        "# Edges\n",
        "graph.add_edge(START, \"get_preferences\")\n",
        "graph.add_edge(\"get_preferences\", \"gen_breakfast\")\n",
        "graph.add_edge(\"get_preferences\", \"gen_lunch\")\n",
        "graph.add_edge(\"get_preferences\", \"gen_dinner\")\n",
        "\n",
        "# Review + Finalize per meal\n",
        "graph.add_edge(\"gen_breakfast\", \"review_bf\")\n",
        "graph.add_edge(\"review_bf\", \"final_bf\")\n",
        "graph.add_edge(\"final_bf\", \"final_review\")\n",
        "\n",
        "graph.add_edge(\"gen_lunch\", \"review_lunch\")\n",
        "graph.add_edge(\"review_lunch\", \"final_lunch\")\n",
        "graph.add_edge(\"final_lunch\", \"final_review\")\n",
        "\n",
        "graph.add_edge(\"gen_dinner\", \"review_dinner\")\n",
        "graph.add_edge(\"review_dinner\", \"final_dinner\")\n",
        "graph.add_edge(\"final_dinner\", \"final_review\")\n",
        "\n",
        "# End\n",
        "graph.add_edge(\"final_review\", END)\n",
        "\n",
        "# -------- Compile & Run --------\n",
        "workflow = graph.compile(checkpointer=memory)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "  display(Image(workflow.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    print(Exception)\n",
        "    #This requires some extra dependencies and is optional\n",
        "    pass\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "result = workflow.invoke({}, config=config, stream_mode=\"updates\")\n",
        "result\n",
        "\n",
        "for chunk in workflow.stream({}, config=config, stream_mode=\"updates\"):\n",
        "    for node_id, value in chunk.items():\n",
        "        if node_id == \"__interrupt__\":\n",
        "            decision = input(\"Approve or Regenerate? (yes/no): \")\n",
        "            if decision == \"yes\":\n",
        "                workflow.invoke(Command(resume=decision), config=config, stream_mode=\"updates\")\n",
        "            # else:\n",
        "            #     goto_node = input(\"Enter node to go to (e.g., gen_breakfast): \")\n",
        "            #     workflow.invoke(Command(goto=goto_node), config=config, stream_mode=\"updates\")\n"
      ]
    }
  ]
}